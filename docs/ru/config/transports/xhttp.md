# XHTTP: За гранью REALITY

## Содержание

1. [Введение](#введение)
2. [Руководство по быстрому старту](#руководство-по-быстрому-старту)
3. [Два базовых принципа](#два-базовых-принципа)
4. [Режим PACKET-UP](#режим-packet-up)
5. [H1 / H2 / H3](#h1--h2--h3)
6. [XMUX - Мультиплексирование соединений](#xmux---мультиплексирование-соединений)
7. [STREAM-UP/ONE](#stream-upone)
8. [Разделение загрузки и выгрузки](#разделение-загрузки-и-выгрузки)
9. [Полная конфигурация](#полная-конфигурация)
10. [Beyond REALITY](#beyond-reality)

---

## Введение

**XHTTP** (ранее известный как **SplitHTTP**) - это революционный транспортный протокол для Xray-core, разработанный в середине 2024 года командой разработчиков, включая @mmmray, @ll11l1lIllIl1lll и других, под руководством @RPRX.

### История разработки

XHTTP был создан на основе принципа **"раздельная пакетная отправка, потоковая загрузка"** и впервые добился обхода большинства промежуточных устройств, поддерживающих HTTP, без ущерба для эффективности загрузки. Это также первый протокол, который массово реализовал QUIC H3 через CDN, открыв новую эру в обходе цензуры.

### Эволюция XHTTP

1. **Первая версия (SplitHTTP)**: Реализация базового принципа раздельной отправки и потоковой загрузки
2. **Browser Dialer**: Добавление поддержки браузерного диаллера
3. **Header Padding**: Добавление отступов в заголовки для уменьшения сигнатуры
4. **XMUX**: Управление мультиплексированием соединений
5. **Разблокировка REALITY**: Интеграция с REALITY
6. **Разделение трафика**: Реализация настоящего разделения исходящего и входящего трафика
7. **Stream-up режим**: Потоковая отправка без потери эффективности
8. **Extra схема**: Возможность делиться всеми деталями конфигурации
9. **Stream-one режим**: Включение транспортного уровня HTTP в XHTTP

### Ключевые достижения

- **Обход промежуточных устройств**: Первый протокол, успешно обходящий большинство HTTP-промежуточных устройств
- **QUIC H3 через CDN**: Массовая реализация QUIC H3 через CDN
- **Разделение трафика**: Возможность использовать разные серверы/IP для upload и download
- **Полная обфускация**: Header padding, XMUX, маскировка заголовков
- **Высокая производительность**: Оптимизированная скорость передачи данных

---

## Руководство по быстрому старту

Несмотря на большое количество параметров XHTTP, большинство из них имеют значения по умолчанию. Для быстрого старта следуйте этим шести шагам:

### Шаг 1: Базовая настройка

Независимо от использования TLS или REALITY, обычно для настройки XHTTP достаточно указать только `path`. Остальные параметры можно оставить пустыми.

```json
{
  "network": "xhttp",
  "xhttpSettings": {
    "path": "/yourpath"
  }
}
```

### Шаг 2: Поддержка QUIC H3

Если сервер поддерживает QUIC H3, клиент может использовать QUIC, выбрав `alpn` равным `"h3"`:

```json
{
  "network": "xhttp",
  "security": "tls",
  "tlsSettings": {
    "alpn": ["h3"]
  },
  "xhttpSettings": {
    "path": "/yourpath"
  }
}
```

### Шаг 3: Использование CDN

Для выбора IP-адреса CDN в клиенте укажите IP-адрес в `address` и доменное имя в `serverName` (SNI):

```json
{
  "address": "1.2.3.4",
  "port": 443,
  "streamSettings": {
    "security": "tls",
    "tlsSettings": {
      "serverName": "cdn.example.com"
    },
    "xhttpSettings": {
      "path": "/yourpath"
    }
  }
}
```

### Шаг 4: Cloudflare

Если не удается подключиться к Cloudflare, включите поддержку gRPC на панели управления CF.

### Шаг 5: Nginx

Если не удается пройти через Nginx, измените `proxy_pass` на `grpc_pass` в конфигурации Nginx.

### Шаг 6: Другие CDN и обратные прокси

Если не удается пройти через другие CDN или обратные прокси, рекомендуется выбрать `mode` равным `"packet-up"` для максимальной совместимости:

```json
{
  "xhttpSettings": {
    "path": "/yourpath",
    "mode": "packet-up"
  }
}
```

### Важные замечания

- **Мультиплексирование**: XHTTP по умолчанию использует мультиплексирование, что обеспечивает меньшую задержку, чем у Vision, но тесты скорости показывают худшие результаты, если не установлено `"maxConcurrency": 1`. См. раздел [XMUX](#xmux---мультиплексирование-соединений).

- **Keep-Alive**: Cloudflare обрывает HTTP-соединения без передачи данных в течение 100 секунд. Для поддержания активности долговременных соединений через прокси необходимо реализовать keep-alive на уровне приложения. Например, для SSH необходимо установить `ClientAliveInterval` в sshd.

---

## Два базовых принципа

### Принцип 1: Увеличение "сопутствующего ущерба"

Так же, как REALITY может маскироваться под чужой веб-сайт, фундаментальная логика борьбы с цензурой заключается в увеличении «сопутствующего ущерба» для цензоров при блокировке, чтобы они не решались легко блокировать.

Многолетний опыт показывает, что GFW не будет навсегда блокировать весь IP-адрес крупного CDN, иначе это затронет слишком много обычных веб-сайтов. Таким образом, для XHTTP первоначальная цель состояла в том, чтобы скрыть его за множеством различных CDN.

### Принцип 2: Потоковая загрузка

CDN, чтобы предотвратить атаки на исходный сервер, обычно кэшируют весь HTTP-запрос, прежде чем отправлять его на исходный сервер, за исключением специально поддерживаемых WebSocket и gRPC. Многие промежуточные HTTP-устройства по умолчанию ведут себя аналогичным образом.

Протокол Meek от Tor упаковывает исходящий и входящий трафик в отдельные HTTP-запросы для обхода этих промежуточных устройств, но скорость ужасно низкая, потому что он не использует «потоковую загрузку» XHTTP.

**Что такое «потоковая загрузка»?**

Представьте, что вы загружаете большой файл с веб-сайта, и CDN не находит его в кэше, поэтому обращается к исходному серверу. Но, очевидно, он не будет кэшировать весь файл, как при загрузке, заставляя вас ждать, а будет немедленно передавать вам данные по мере их получения от исходного сервера. Это основа «потоковой загрузки» XHTTP, которая также гарантирует максимальную скорость загрузки.

### Пакетная загрузка

Что касается загрузки, то из соображений совместимости XHTTP сначала реализовал «пакетную загрузку», то есть упаковку исходящего трафика в отдельные POST-запросы. Его эффективность, очевидно, снижается, но, к счастью, для обычных прокси-серверов объем исходящего трафика очень мал. Позже был добавлен режим «потоковой загрузки» (stream-up), и после нескольких раундов оптимизации «пакетной загрузки» скорость даже приблизилась к «потоковой загрузке».

---

## Режим PACKET-UP

Режим `packet-up` обеспечивает максимальную совместимость XHTTP, реализуя принцип **"пакетная загрузка, потоковая выгрузка"**.

### Архитектура режима packet-up

#### 1. Загрузка данных (Upload)

Клиент отправляет POST-запросы для передачи данных:

- **Формат URL**: `POST /yourpath/{sessionId}/{seq}`
- **UUID (sessionId)**: Генерируется случайным образом при запуске загрузки, чтобы сервер мог связать запросы. Если сервер не может связать запросы в течение 30 секунд, сеанс завершается.
- **seq**: Начинается с 0. Следующий POST-запрос можно отправлять только после отправки тела предыдущего (но не нужно ждать ответа).
- **Переупорядочивание**: Несколько POST-запросов могут прийти на сервер в неправильном порядке. Сервер пересобирает их по seq. По умолчанию кэшируется до 30 запросов, превышение лимита приводит к разрыву соединения.
- **Важно**: UUID и seq находятся в пути, а не в строке запроса, чтобы избежать странных проблем.

#### 2. Выгрузка данных (Download)

Клиент запускает выгрузку с помощью GET-запроса: `GET /yourpath/{sessionId}`

Заголовки ответа сервера содержат:

- **X-Accel-Buffering: no**: Сообщает промежуточным устройствам отключить буферизацию
- **Cache-Control: no-store**: Сообщает промежуточным устройствам не кэшировать данные
- **Content-Type: text/event-stream**: Маскировка под server-sent events (лучшая совместимость, можно отключить с помощью `noSSEHeader`)
- **Transfer-Encoding: chunked**: Для HTTP/1.1 (для H2/H3 не требуется)

#### 3. CORS заголовки

Чтобы избежать ограничений междоменных запросов при перенаправлении браузера Browser Dialer, заголовок ответа сервера для всех GET и POST-запросов содержит:

- **Access-Control-Allow-Origin: \***
- **Access-Control-Allow-Methods: GET, POST**

#### 4. Header Padding

Для решения проблемы фиксированной длины заголовков HTTP-запросов и ответов:

- **Заголовок запроса клиента**: По умолчанию содержит `Referer: ...?x_padding=XXX...` (Referer используется для предотвращения ненужных OPTIONS-запросов от Browser Dialer). Длина по умолчанию составляет 100-1000 символов, генерируется случайным образом для каждого запроса. Сервер по умолчанию проверяет, находится ли длина в допустимом диапазоне.
- **Заголовок ответа сервера**: По умолчанию содержит `X-Padding: XXX....` Длина по умолчанию составляет 100-1000 символов, генерируется случайным образом для каждого ответа.
- **Параметр**: `xPaddingBytes`
- **Оптимизация**: Размещение padding в Referer предложил @rPDmYQ, использование символа 'X' также его идея. 'X' в кодировке Хаффмана занимает 8 бит, что оптимизирует сжатие HPACK/QPACK.

### Параметры packet-up

Для реализации и ограничения POST-запросов используются три специальных параметра:

#### `scMaxEachPostBytes`

- **Описание**: Максимальный размер данных в каждом POST-запросе клиента
- **Значение по умолчанию**: 1000000 (1 МБ)
- **Важно**: Это значение должно быть меньше максимального размера, разрешенного CDN и другими промежуточными HTTP-устройствами. Сервер также отклоняет POST-запросы, превышающие этот размер.
- **Поддержка диапазона**: Можно задать в виде диапазона, например `"500000-1000000"`, со случайным выбором значения для каждого запроса

#### `scMinPostsIntervalMs`

- **Описание**: Минимальный интервал между POST-запросами для одного прокси-запроса (только для клиента)
- **Значение по умолчанию**: 30 миллисекунд
- **Поддержка диапазона**: Можно задать в виде диапазона, например `"10-50"`, со случайным выбором значения
- **Назначение**: Используется для ограничения частоты запросов и обфускации

#### `scMaxBufferedPosts`

- **Описание**: Максимальное количество кэшируемых POST-запросов для одного прокси-запроса (только для сервера)
- **Значение по умолчанию**: 30
- **Назначение**: Превышение лимита приводит к разрыву соединения для предотвращения переполнения памяти

**Примечание**: «Для одного прокси-запроса» означает, что каждый прокси-запрос имеет свой счетчик и не влияет на другие, даже если они находятся в одном H2/H3 соединении. Это значение `sc`, то есть sub-connection.

### Оптимизация packet-up

В последней версии Xray был оптимизирован packet-up, и его скорость теперь почти достигает stream-up, что особенно полезно для QUIC H3 через CDN.

### Логирование

Пакетная загрузка и Referer с `x_padding` создают много длинных записей в журнале. Вы можете настроить обратный прокси-сервер, чтобы он не регистрировал их.

### Дополнительные возможности

Как и другие транспортные уровни Xray, сервер принимает заголовок `X-Forwarded-For` для получения реального IP-адреса клиента и проверяет `host`, отправленный клиентом, на основе настройки `host` на сервере (рекомендуется не устанавливать его без необходимости, так как он уже скрыт в пути).

---

## H1 / H2 / H3

### Особенности HTTP-посредников

Особенностью многих HTTP-посредников, таких как CDN и Nginx, является преобразование версии HTTP. Например, они могут преобразовывать входящий трафик H3 в H1 или H2 при обращении к исходному серверу. Это означает, что наш сервер XHTTP может прослушивать только H1 и H2, без необходимости прослушивания H3, в то время как клиент XHTTP может использовать H3.

### Поведение сервера XHTTP

**По умолчанию**: Сервер прослушивает только TCP-порт и обрабатывает трафик H1 и H2.

**При включении H3**: При включении TLS и указании только `"h3"` в `alpn` сервер будет использовать quic-go для прослушивания UDP-порта и обработки трафика H3, но в настоящее время это не рекомендуется. Вместо этого следует скрывать XHTTP за реальными Nginx или Caddy, чтобы уменьшить цифровые отпечатки.

**Преимущества XHTTP**:
- Одно из важных преимуществ XHTTP по сравнению с другими QUIC-прокси - возможность проходить через CDN
- Другое преимущество - управление перегрузкой H3 реализовано на уровне приложения, теоретически вы можете изменить алгоритмы управления перегрузкой QUIC этих обратных прокси-серверов и скомпилировать их, чтобы реализовать агрессивную отправку пакетов

### Поведение клиента XHTTP

#### Автоматический выбор версии HTTP

Логика выбора версии HTTP:

1. **При включении TLS/REALITY**: По умолчанию используется H2
2. **Без TLS**: Используется HTTP/1.1
3. **При включении TLS, если alpn содержит только "http/1.1"**: Используется HTTP/1.1 (но Xray не позволит изменить маскировку цифрового отпечатка браузера uTLS)
4. **При включении TLS, если alpn содержит только "h3"**: Используется quic-go H3
5. **При использовании Browser Dialer**: Конкретная версия HTTP определяется браузером (весь `tlsSettings` игнорируется)

#### Определение фактической версии HTTP

Если вам нужно узнать фактическую версию HTTP, используемую клиентом Xray, `host`, а также режим XHTTP, разделение загрузки и выгрузки и другую информацию, установите уровень ведения журнала `"info"`.

### QUIC H3 через CDN

Проксирование QUIC H3 через CDN - это достижение, которое XHTTP реализовал первым в больших масштабах, открыв новый путь. В некоторых регионах и у некоторых операторов связи цензура H3 не так строга, хотя у некоторых она может быть очень жесткой.

Даже после разработки режима stream-up и обнаружения, что можно проходить через Cloudflare с помощью маскировки заголовка gRPC, это работало только для H2, похоже, ценность этой новой эры продолжает расти.

---

## XMUX - Мультиплексирование соединений

### Обзор

Раз уж мы упомянули H2 и H3, нельзя не упомянуть их мультиплексирование: оба имеют 0-RTT. Разница в том, что у H3 нет проблемы блокировки TCP, как у H2, и он поддерживает миграцию соединения, поэтому переключение сети на стороне клиента не приведет к разрыву соединения.

XMUX - это простой и мощный интерфейс для управления мультиплексированием соединений.

### Параметры XMUX

#### `maxConcurrency`

- **Описание**: Максимальное количество одновременных прокси-запросов в каждом TCP/QUIC-соединении
- **Значение по умолчанию**: Если все параметры XMUX равны 0, значение по умолчанию — `"16-32"`, выбирается случайным образом. Иначе — 0 (без ограничений)
- **Как работает**: Когда количество прокси-запросов в соединении достигает этого значения, ядро устанавливает новое соединение, чтобы вместить больше прокси-запросов
- **Поддержка диапазона**: Поддерживается указание диапазона, значение выбирается случайным образом

#### `maxConnections`

- **Описание**: Максимальное количество одновременных соединений
- **Значение по умолчанию**: 0 (без ограничений)
- **Как работает**: До достижения этого значения каждый новый прокси-запрос открывает новое соединение. После этого ядро начинает повторно использовать существующие соединения
- **Конфликт**: Этот параметр конфликтует с `maxConcurrency`, можно использовать только один из них
- **Поддержка диапазона**: Поддерживается указание диапазона, значение выбирается случайным образом

#### `cMaxReuseTimes`

- **Описание**: Максимальное количество раз, которое соединение может быть повторно использовано
- **Значение по умолчанию**: 0 (без ограничений)
- **Как работает**: После достижения этого количества соединение больше не будет использоваться для новых прокси-запросов и будет закрыто после завершения последнего прокси-запроса
- **Поддержка диапазона**: Поддерживается указание диапазона, значение выбирается случайным образом

#### `hMaxRequestTimes`

- **Описание**: Максимальное количество HTTP-запросов на каждое TCP/QUIC-соединение
- **Значение по умолчанию**: Если все параметры XMUX равны 0, значение по умолчанию — `"600-900"`, выбирается случайным образом. Иначе — 0 (без ограничений)
- **История**: @xqzr обнаружил, что Nginx по умолчанию разрешает максимум 1000 HTTP-запросов на каждое TCP/QUIC-соединение
- **Как работает**: Этот параметр основан на подсчете HTTP-запросов. Обычно stream-one генерирует один HTTP-запрос, stream-up — два, а packet-up — N. Подсчет не является точным, и GET-запросы Golang имеют автоматический повтор, поэтому не рекомендуется устанавливать максимальное значение
- **Особенность**: Если при циклической отправке POST-запросов в режиме packet-up это значение превышено, происходит автоматическое переключение на другое TCP/QUIC-соединение, которое занимает один reuseTimes, но не занимает concurrency
- **Поддержка диапазона**: Поддерживается указание диапазона, значение выбирается случайным образом

#### `hMaxReusableSecs`

- **Описание**: Максимальное время жизни TCP/QUIC-соединения в секундах
- **Значение по умолчанию**: Если все параметры XMUX равны 0, значение по умолчанию — `"1800-3000"`, выбирается случайным образом. Иначе — 0 (без ограничений)
- **История**: @xqzr обнаружил, что Nginx по умолчанию разрешает повторное использование каждого TCP/QUIC-соединения в течение одного часа
- **Как работает**: TCP/QUIC-соединение, существующее в течение этого времени, больше не будет использоваться для новых HTTP-запросов и будет закрыто после завершения последнего HTTP-запроса. Если при циклической отправке POST-запросов в режиме packet-up это значение превышено, происходит автоматическое переключение на другое TCP/QUIC-соединение, которое занимает один reuseTimes, но не занимает concurrency
- **Поддержка диапазона**: Поддерживается указание диапазона, значение выбирается случайным образом

#### `hKeepAlivePeriod`

- **Описание**: Интервал в секундах, через который клиент отправляет keep-alive пакет в неактивном H2/H3 соединении
- **Значение по умолчанию**: 0 (что соответствует 45 секундам для Chrome H2 или 10 секундам для quic-go H3)
- **Особенности**: 
  - Это единственный параметр в XMUX, который не допускает указание диапазона (случайный выбор значения будет являться признаком)
  - Допускает отрицательные значения (например, -1 отключает keep-alive пакеты в неактивном состоянии)
- **Рекомендация**: Рекомендуется оставить значение 0

### Комбинирование параметров XMUX

Параметры XMUX можно комбинировать различными способами:

- **Для многопоточного тестирования скорости**: Необходимо установить `"maxConcurrency": 1`
- **Для «бесконечного» повторного использования**: Можно установить `"maxConnections": 1`

### Значения по умолчанию

**Важно**: Отсутствие значений эквивалентно нулевым значениям, будут использованы три значения по умолчанию (`maxConcurrency: "16-32"`, `hMaxRequestTimes: "600-900"`, `hMaxReusableSecs: "1800-3000"`). Но если указан хотя бы один параметр, остальные параметры не имеют значений по умолчанию и должны быть указаны явно, за исключением первых двух параметров (`maxConcurrency` и `maxConnections`). Все остальные параметры можно указывать одновременно.

### Особенности значений по умолчанию

Разработчики специально выбрали два параметра, которые не так заметны вне TLS, а именно `maxConcurrency` и `cMaxReuseTimes` (а не `maxConnections` и `cLifetimeMs`), и значения по умолчанию для этих параметров являются диапазоном со случайным выбором, что максимально устраняет потенциальные признаки.

Было выбрано `maxConcurrency` вместо `maxConnections`, чтобы предотвратить появление фиксированного шаблона количества соединений. Конечно, если вам нравится второй вариант, вы можете установить его вручную.

### Объекты подсчета

XMUX и Nginx имеют разные объекты подсчета. `maxConcurrency` и `cMaxReuseTimes` основаны на подсчете «проксируемых соединений». Только stream-one генерирует один HTTP-запрос, stream-up — два (один для загрузки, один для выгрузки), а packet-up — N.

Однако разработчики не уверены, что stream-one не будет генерировать дополнительные HTTP-запросы в некоторых случаях. Кроме того, стремление к повторному использованию одного соединения до конца не имеет большого смысла, потому что если бы вы были оператором связи, вы бы также ограничивали скорость и очищали старые соединения, иначе ресурсы были бы постепенно заняты старыми соединениями. Поэтому параметры XMUX по умолчанию ограничивают повторное использование и периодически меняют соединения.

### Передача параметров

Эти параметры можно передать клиенту через `extra`, это описано в разделе [Полная конфигурация](#полная-конфигурация).

### Важное примечание

При использовании XHTTP не следует включать `mux.cool`. Новая версия сервера Xray имеет проверку и принимает только чистый XUDP.

---

## STREAM-UP/ONE

### Обзор

Режим **stream-up** реализует принцип **"потоковая загрузка, потоковая выгрузка"**. Как следует из названия, в этом режиме загрузка также является потоковой, что не снижает ее эффективность.

### История разработки

Он был первоначально разработан для REALITY, пока не обнаружили, что маскировка заголовка gRPC под H2 позволяет проходить через Cloudflare (необходимо включить поддержку gRPC в панели управления), и обратные прокси-серверы, такие как Nginx, также хорошо его поддерживают (для Nginx рекомендуется `grpc_pass`, это просто и удобно).

### Автоматический выбор режима

Поведение `mode` со значением по умолчанию `"auto"` следующее:

**Клиент**:
- `stream-up` для TLS H2
- `stream-one` для REALITY (stream-up при наличии `downloadSettings`)
- В противном случае `packet-up`

**Сервер**:
- По умолчанию принимает все три режима
- Если задан конкретный режим, принимается только он
- `"stream-up"` является исключением, он также принимает `stream-one`

### Сравнение режимов

`stream-up` имеет немного лучшую совместимость, чем `stream-one`. Участники группы сообщали, что Cloudflare с включенной потоковой загрузкой может использовать stream-up, но требуется включить еще одну опцию для использования stream-one (возможно, проблема в маскировке SSE?). Также видели CDN, который сильно ограничивал скорость stream-one, но не stream-up.

### Реализация stream-up

Для stream-up достаточно заменить пакетную загрузку packet-up на потоковую `POST /yourpath/{sessionId}`. Также используется `Referer: ...?x_padding=XXX....`

### Реализация stream-one

Для stream-one используется `POST /yourpath/`. Ответ является выгрузкой, двунаправленный поток. Заголовки запроса и ответа имеют header padding.

**Важно**: Если для stream-one указан `/yourpath`, фактический запрос отправляется на `/yourpath/`. Если `/` в конце отсутствует, он добавляется автоматически.

### Заголовки

- **Загрузка по умолчанию**: Имеет `Content-Type: application/grpc` для маскировки под gRPC (можно отключить с помощью `noGRPCHeader`)
- **Заголовки ответа сервера для выгрузки**: Идентичны заголовкам packet-up (`X-Accel-Buffering: no`, `Cache-Control: no-store`, `Content-Type: text/event-stream`)
- **Особенность stream-one**: Может возникнуть необычная ситуация, когда gRPC отвечает с помощью SSE. Если возникнут проблемы, попробуйте `noSSEHeader`

### Keep-Alive для stream-up

В ходе тестов было обнаружено, что Cloudflare обрывает HTTP-соединения без передачи данных в течение 100 секунд, что приводит к обрыву загрузки stream-up. Поэтому был добавлен параметр `scStreamUpServerSecs` на сервер со значением по умолчанию `"20-80"` (выбирается случайным образом). Сервер каждые этот интервал отправляет `xPaddingBytes` байт для поддержания активности соединения.

Можно установить `"scStreamUpServerSecs": -1`, чтобы отключить этот механизм. В этом случае сервер даже не будет отправлять заголовки ответа своевременно, как в предыдущих версиях.

### Преимущества stream-up по сравнению с gRPC

1. Первому не нужны никакие библиотеки gRPC, производительность выше
2. Исходящий трафик первого — это отдельные GET-запросы, не подверженные ограничениям CDN для трафика gRPC
3. Первый также имеет header padding, XMUX, разделение загрузки и выгрузки и другие улучшения, и уже внедрен механизм extra, все параметры можно передавать, более зрелое решение

### Преимущества XHTTP по сравнению с WebSocket и HTTPUpgrade

Помимо «отсутствия явного признака ALPN как http/1.1», XHTTP имеет множество преимуществ:
- Потоковая загрузка
- Header padding
- XMUX
- Разделение загрузки и выгрузки
- Поддержка QUIC H3 через CDN
- И многие другие

---

## Разделение загрузки и выгрузки

### Обзор

Еще одна новая эра: разделение загрузки и выгрузки. Мы примерно знаем, что сейчас GFW обнаруживает такие характеристики трафика, как TLS in TLS, на основе одного соединения. Таким образом, если мы разделим загрузку и выгрузку на разные соединения, например, загрузка будет идти по TCP через IPv4, а выгрузка — по UDP через IPv6, GFW не сразу сможет сориентироваться.

### Техническая реализация

Поскольку сервер XHTTP связывает загрузку и выгрузку только на основе случайно сгенерированного UUID в пути, packet-up и stream-up изначально обладают настоящей способностью разделять загрузку и выгрузку. И поскольку XHTTP может проходить через различные CDN, может сочетаться с REALITY и другими технологиями, количество возможных вариантов бесконечно.

### Конфигурация downloadSettings

Для клиента необходимо настроить `downloadSettings`:

```json
{
  "xhttpSettings": {
    "host": "example.com",
    "path": "/yourpath",
    "mode": "auto",
    "downloadSettings": {
      "address": "",
      "port": 443,
      "network": "xhttp",
      "security": "tls",
      "tlsSettings": {
        "serverName": "download.example.com"
      },
      "xhttpSettings": {
        "path": "/yourpath",
        "host": "download.example.com"
      },
      "sockopt": {}
    }
  }
}
```

### Структура downloadSettings

`downloadSettings` — это, по сути, новый набор `streamSettings`, но с добавлением `address` и `port`, аналогичных исходящему VLESS, для указания другого входа. Очевидно, что `network` должен быть `"xhttp"` (нельзя опускать), `security` может быть `"tls"` или `"reality"`.

### Параметр sockopt

Параметр `sockopt` также можно передавать, но принимающая сторона может установить `penetrate` в значение `true` в `sockopt` загрузки, чтобы переопределить выгрузку, что подходит для использования `mark`. За исключением этого особого случая, при разделении загрузки и выгрузки конфигурация выгрузки полностью независима и не наследует никакие настройки загрузки.

### Независимость конфигураций

Более того, например, даже если XMUX не указан ни для загрузки, ни для выгрузки, и используются значения по умолчанию, фактические значения, выбранные случайным образом из диапазона, независимы друг от друга. Таким образом, со временем повторное использование загрузки и выгрузки становится полностью асимметричным, моменты переключения основного соединения также различаются, что улучшает защиту от анализа.

### Будущие улучшения

Поскольку, если GFW захочет бороться с разделением загрузки и выгрузки, «одинаковое время запуска основного соединения» определенно будет самой важной точкой входа. Поэтому в будущем XHTTP позволит запускать соединения загрузки и выгрузки в разное время с самого начала.

### Примеры использования

#### Использование CDN без изменения конфигурации сервера

Если вы используете CDN, вы можете использовать разделение загрузки и выгрузки, даже не изменяя конфигурацию сервера. Например, вы можете выбрать IPv4 для TLS H2 и IPv6 для QUIC H3.

#### Префикс одного домена

CDN обычно поддерживают «префикс одного домена». Например, `serverName` для загрузки может быть `"a.example.com"`, `serverName` для выгрузки — `"b.example.com"`, а `host` для обоих — `"c.example.com"`. Это позволяет сделать внешние SNI разными.

#### Два домена

Если у вас уже есть два домена, это еще лучше.

#### Два VPS и два REALITY

Если у вас нет доменов, вы можете использовать два VPS и два REALITY для разделения загрузки и выгрузки: будь то CDN с обратным прокси или REALITY с fallback, главное, чтобы в итоге трафик с одним и тем же путем попадал на один и тот же входящий XHTTP на одном и том же VPS.

### Практические применения

#### Разделение по качеству каналов

После появления разделения загрузки и выгрузки многие используют его для разделения загрузки на канал с лучшим исходящим трафиком, а выгрузки — на канал с лучшим входящим трафиком, что также довольно практично.

#### Оптимизация для разных типов трафика

Например, вы можете установить `"maxConnections": 1` для загрузки и `"maxConcurrency": 1` для выгрузки, чтобы небольшой объем данных загрузки шел по одному и тому же базовому соединению, а большой объем данных выгрузки распределялся по разным базовым соединениям, одновременно обеспечивая защиту от цензуры, низкую задержку и высокую скорость. Это похоже на Switch, и лучше всего работает в сочетании с Vision Seed.

---

## Полная конфигурация

Ниже приведен пример конфигурации со всеми параметрами, главным образом для того, чтобы показать, где должен быть каждый параметр, и объяснить параметры, которые не были подробно рассмотрены в тексте:

```json
{
  "xhttpSettings": {
    "host": "example.com",
    "path": "/yourpath",
    "mode": "auto",
    "extra": {
      "headers": {
        "User-Agent": "Mozilla/5.0..."
      },
      "xPaddingBytes": "100-1000",
      "noGRPCHeader": false,
      "noSSEHeader": false,
      "scMaxEachPostBytes": 1000000,
      "scMinPostsIntervalMs": 30,
      "scMaxBufferedPosts": 30,
      "scStreamUpServerSecs": "20-80",
      "xmux": {
        "maxConcurrency": "16-32",
        "maxConnections": 0,
        "cMaxReuseTimes": 0,
        "hMaxRequestTimes": "600-900",
        "hMaxReusableSecs": "1800-3000",
        "hKeepAlivePeriod": 0
      },
      "downloadSettings": {
        "address": "",
        "port": 443,
        "network": "xhttp",
        "security": "tls",
        "tlsSettings": {
          "serverName": "download.example.com"
        },
        "xhttpSettings": {
          "path": "/yourpath",
          "host": "download.example.com"
        },
        "sockopt": {}
      }
    }
  }
}
```

### Параметр extra

`extra` — это оригинальное решение для передачи всех параметров, кроме `host`, `path` и `mode`, в формате JSON. Когда `extra` присутствует, действуют только эти четыре параметра (`host`, `path`, `mode`, `extra`). И в ссылке для общего доступа есть только эти четыре параметра, как и в большинстве GUI, потому что параметры в `extra` используются относительно редко и должны предоставляться клиенту непосредственно поставщиком услуг, а не изменяться клиентом произвольно.

**Дополнение**: «предоставляться» означает «предоставляться человеком», то есть поставщик услуг записывает `extra` и помещает его в ссылку для общего доступа, клиент использует его непосредственно как свой `extra`.

### Параметр host

Поведение `host` аналогично другим транспортным уровням Xray, основанным на HTTP. Приоритет отправки `host` клиентом: `host` > `serverName` > `address`. Если на сервере установлен `host`, он проверяет, совпадает ли значение, отправленное клиентом. В противном случае проверка не выполняется. Рекомендуется не устанавливать его без необходимости. `host` нельзя указывать в `headers`.

### Логирование

Если вам нужно узнать фактическую версию HTTP, используемую клиентом Xray, `host`, а также режим XHTTP, разделение загрузки и выгрузки и другую информацию, установите уровень ведения журнала `"info"`.

---

## Beyond REALITY

### Введение

В начале прошлого года был написан REALITY, одним махом решив несколько проблем. REALITY вырос в основную технологию для прямого подключения. Часто можно увидеть комментарии под сообщениями о блокировке с рекомендацией перейти на REALITY, репутация говорит сама за себя.

### XHTTP как новый этап

Хотя Xray также внес множество оптимизаций и улучшений в другие транспортные протоколы, XHTTP — это первый нативный транспортный уровень Xray, сразу же сделавший большой шаг.

**Beyond REALITY** означает не замену REALITY, а превзойдение REALITY по популярности. Без преувеличения, как это всегда было в стиле Xray, появление XHTTP затмевает все другие транспортные уровни на основе HTTP.

### Эпоха всеобщего господства XHTTP

Это эпоха всеобщего господства XHTTP. Он станет более популярным, чем предыдущий успешный протокол REALITY, потому что характеристики XHTTP уже определяют его более широкое применение.

### Использование XHTTP с REALITY

Прочитав эту статью, вы также поймете, что XHTTP можно использовать вместе с REALITY, создавая еще более мощные комбинации для обхода цензуры.

### Заключение

Наконец, надеемся, что появление XHTTP немного потрясет всех, как это неоднократно делал Xray в своей истории: инновации и постоянное обновление — это кредо Xray.

---

## Дополнительные ресурсы

- [Официальный репозиторий Xray-core](https://github.com/XTLS/Xray-core)
- [Обсуждение XHTTP](https://github.com/XTLS/Xray-core/discussions/4113)
- [Telegram канал Project XHTTP](https://t.me/projectXhttp)

---

**Версия документации**: 2.0  
**Последнее обновление**: 2024  
**Основано на**: Оригинальной статье "XHTTP: За гранью REALITY" и анализе исходного кода Xray-core
